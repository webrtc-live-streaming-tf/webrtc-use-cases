<!DOCTYPE html>
<html lang="en">

<head>
  <title>WebRTC Use Cases and Requirements for Live Streaming Multimedia Ecosystem</title>
  <meta charset='utf-8'>
  <link rel="stylesheet" href="./local.css" />
  <script src='https://www.w3.org/Tools/respec/respec-w3c' async class='remove'></script>
  <script class='remove'>
    var respecConfig = {
      specStatus: "CG-DRAFT",
      shortName: "webrtc-live-streaming-use-cases",
      edDraftURI: "https://webrtc-live-streaming-tf.github.io/webrtc-use-cases/",
      editors: [],
      wg: "Chinese Web Interest Group",
      wgURI: "https://www.w3.org/2018/chinese-web-ig/",
      github: {
        repoURL: "https://github.com/webrtc-live-streaming-tf/webrtc-use-cases",
        branch: "main"
      },
    };
  </script>
</head>

<body>
  <section id='abstract'>
    <p>
      This document describes use cases and requirements for WebRTC used in Live Streaming Multimedia Ecosystem .
    </p>
  </section>
  <section id='sotd'>
    <p>
      This is still a work in progress. The proposal is being incubated in the <a
        href="https://www.w3.org/2018/chinese-web-ig/">Chinese Web Interest Group</a>.
    </p>
  </section>
  <section>
    <h2>Introduction</h2>
    <p>
      The current livestreaming multimedia ecosystem is showing diverse and robust growth trends. It covers
      livestreaming content from both institutions and individuals in various fields to meet the diverse needs of users.
      In this ecosystem, major tech companies are strategically involved in different areas to provide richer,
      practical, and entertaining livestreaming experiences.

    </p>

    <p>

      Alibaba Group demonstrates strong capabilities in the livestreaming sector. Its livestreaming e-commerce combines
      shopping and entertainment, offering consumers immersive shopping experiences. Through methods like hosts
      showcasing products and interactive Q&A sessions, consumers are engaged in making purchases. Additionally, Alibaba
      also offers fundamental livestreaming cloud services, spanning education and gaming sectors, providing technical
      support for creating livestreaming platforms for businesses and individuals.

    </p>

    <p>

      Chia Mobile MiGu, an integrated media platform, focuses on providing diverse livestreaming content. Particularly
      in
      large-scale event livestreaming, MiGu offers real-time broadcasts of significant events like sports competitions
      and music concerts, meeting users' demand for immediate experiences. Moreover, MiGu experiments with
      virtual-physical interactions using technologies like digital avatars, creating a more enriched virtual
      interactive experience for users.


    </p>

    <p>
      ByteDance plays a crucial role in interactive entertainment, online education, and conferencing. Its TikTok
      platform has become a globally popular short video platform, providing users with abundant entertainment content,
      including livestreaming. ByteDance has also ventured into livestreamed educational content to accommodate learners
      seeking flexible learning approaches. In the business sector, its livestreamed conferencing solutions offer
      efficient remote communication and collaboration platforms for enterprises.
    </p>
  </section>

  <section>
    <h2>Terminology</h2>
    <p>
      This document uses the following terms with the specific meanings defined here. Where possible these meanings are
      consistent with common usage. However, note that common usage of some of these terms have multiple, ambiguous, or
      inconsistent meanings. The definition here will take precedence. When terms are used with the specific meanings
      defined here they will be capitalized. When possible reference to existing standards defining these terms is
      given.
    </p>
    <dl>
      <dt><dfn class="lint-ignore">WebRTC</dfn></dt>
      <dd>Web Real-Time Communication</dd>
    </dl>
  </section>


  <section>
    <h2>Use Cases</h2>
    <section>
      <h2 id="uc-cb">Cloud Box (UC-CB)</h2>

      <p>
        A "Cloud Box" can be understood as a cloud-based private room, similar to the private room we have in our real
        lives. Friends can come together in these rooms to chat, watch movies, and watching sports events. In sports
        broadcasts, fans can participate in predictions and discussions about ongoing matches through the "Cloud Box"
        feature, enabling them to share their insights and forecasts in real-time. The Cloud Box feature bridges the gap
        between individuals, enhancing their immersive experience and interaction.
      </p>

      <p>
        In this scenario, participants can engage in real-time interactions through WebRTC.
      </p>

      <p>In order to provide a more immersive user experience, spatial audio codecs similar to Dolby Atmos is utilized in WebRTC when watching Ultra HD sports events.</p>

      <figure id="fig-uc-cb">
        <img alt="WebMedia" src="images/UC-CB.png" width="300">
        <figcaption><span>MIGU Cloud Box</span></figcaption>
      </figure>
    </section>




    <section>
      <h2 id="UC-RLC">Real-time Live Commerce (UC-RLC)</h2>
      <p>

        Real-time Live Commerce, also known as real-time livestream shopping, is an innovative retail trend that merges
        real-time streaming
        with e-commerce. In Live Commerce sessions, businesses and brands showcase their products or services on live
        online platforms, such as social media and e-commerce websites, while simultaneously engaging with the audience
        in direct interactions. During these live sessions, hosts or salespeople introduce product features, demonstrate
        usage, address viewer inquiries, and offer exclusive deals or limited-time promotions.

      </p>

      <p>
        Viewers can actively participate by using real-time commenting or chat features to interact with the hosts. They
        can ask questions, express their interest in purchasing, and even share their own product experiences with
        fellow viewers. When a viewer shows interest in a particular product, they can instantly make a purchase using
        dedicated links or designated purchasing methods.
      </p>

      <p>
        Occasionally, invited guests can participate in live interactions with the hosts, aiding in sales through WebRTC-powered video/audio chat.      
      </p>

      <figure id="fig-uc-cb">
        <img alt="WebMedia" src="images/UC-RLC.png" width="300">
        <figcaption><span>Real-time Live Commerce</span></figcaption>
      </figure>

    </section>


    <section id="uc-mcc">
      <h2>Metaverse Convetion Center (UC-MCC)</h2>
      <p>

        The Metaverse Convention Center is a type of cloud game that incorporates advanced technologies such as WebRTC for interactive communication, 3D rendering, and AI-generated avatars. It transforms traditional audio-video conferencing into virtual, gamified, and interactive experiences for remote meetings, office use, and events. 
  

      </p>

      <p>
        Users have the ability to create their own virtual characters, which can range from cartoon-style to realistic representations, and select from a variety of meeting rooms to align with their preferences.
      </p>

      <p>
        In this scenario, all the resources are rendered on the cloud and then streamed to the browser using WebRTC. Any control commands in the browser are executed based on WebRTC.
      </p>

      <figure id="fig-uc-mcc">
        <img alt="WebMedia" src="images/UC-MCC.png" width="600">
        <figcaption><span>MIGU Metaverse Convetion Center</span></figcaption>
      </figure>

    </section>

  </section>


  <section>

    <h2>Requirements</h2>

    <section id="r1-uc-cb">
      <h2>Generic Fragmentation and Reassembly Mechanism for Audio Transmission</h2>

      <p>This requirement is for <a href="#uc-cb">UC-CB</a>.</p>

      <p>

      During audio transmission via WebRTC, RTP packets encapsulate each audio frame. However, if the frame size exceeds the network's MTU limit (typically 1500 bytes), packet transmission can fail. To overcome this, packet fragmentation and reassembly are needed. Fragmentation occurs at the sender, and reassembly happens at the receiver.
      </p>

      <p>
        WebRTC handles fragmentation and  reassembly for video transmission, but not for audio. It is the responsibility of the application or developer to handle fragmentation and reassembly of audio packets when using WebRTC for audio transmission.
      </p>

      <p>A proposed fragmentation and reassembly workflow can be outlined as follows: </p>

      <figure id="fig-uc-cb">
        <img alt="WebMedia" src="images/UC-CB-R1.png" width="600">
        <figcaption><span>a proposed Fragmentation and Reassembly Workflow</span></figcaption>
      </figure>

    </section>


  
    <section id="r3-uc-statistics">
      <h2>Statistics for Audio and Video Freeze</h2>

      <p>This requirement is for <a href="#uc-cb">UC-CB</a>, <a href="#uc-mcc">UC-MCC</a>,  and <a href="#UC-RLC">UC-RLC</a>.</p>


      <p>In the W3C <a href="https://www.w3.org/TR/webrtc-stats/">Identifiers for WebRTC's Statistics API</a> spec, the logic for marking a video freeze, is defined as follows(see <a href="https://www.w3.org/TR/webrtc-stats/#dom-rtcinboundrtpstreamstats-freezecount">freezeCount</a>):
        <ol>
          <li>
            Calculate the linear average of the past 30 rendering frame durations and label it as avg_frame_duration_ms.
          </li>
          <li>
            Calculate the interval between the current two frames. If this value is greater than Max(3 * avg_frame_duration_ms, avg_frame_duration_ms + 150), it is considered as a freeze.
          </li>
        </ol>
        In situations where the network is good, this logic is quite reasonable. However, in the case of a weak network, the value of <code>avg_frame_duration_ms</code> may be larger, for example, 150ms. In this scenario, the freeze trigger value would be 450ms, which may not be reasonable. As generally, 200ms might be considered a freeze. So The spec can define  an API for setting the trigger duration for video freeze (i.e., when the interval between two frames exceeds this duration, it is recorded as a freeze event).
      </p>

      <p>
        Meanwhile, The W3C spec does not define metrics for audio-related freeze , although the underlying WebRTC code has already implemented them with the fields <code>totalInterruptionDuration</code> and <code>interruptionCount</code>. The metrics can be exposed to developers.

      </p>

    </section>

    <section id="r2-uc-cb">
      <h2>Receiving sounds from other devices when in background</h2>

      <p>This requirement is for <a href="#uc-cb">UC-CB</a>.</p>

      <p>
        An iOS device that has the microphone enabled and then switches to the background is unable to hear sounds from
        other devices when some device unmutes.
      </p>

      <p>
        This issue can be reproduced as follows:

      <ul>
        <li>Devices A and B join a WebRTC conference, B is an iOS device, A is any device</li>
        <li>Device A activates the microphone.</li>
        <li>Device B goes to the background (e.g., Home button).</li>
        <li>Device A's voice is audible to B.</li>
        <li>Device A mutes its microphone.</li>
        <li>Device A unmutes and speaks.</li>
        <li>Device B can't hear A, even if B goes back to the foreground.</li>
      </ul>

      </p>

    </section>
    
    
    <section id="r4-uc-gop">
      <h2>Fixed GOP encode interval</h2>

      <p>This requirement is for <a href="#UC-RLC">UC-RLC</a>.</p>

      <p>In the live-streaming scene, the encoder needs to output video frames at a fixed GOP interval (such as GOP=2 seconds). We hope that an API can be provided to set GOP interval.</p>

    </section>

    
    <section id="r5-uc-rtcpxr">
      <h2>Enable RTCP-XR (RRTR/DLRR) at recv-only mode</h2>

      <p>This requirement is for <a href="#UC-RLC">UC-RLC</a>.</p>

      <p>In the live-streaming scene, the player endpoint is generally in recv-only mode. If the player endpoint wants to calculate RTT (round-trip time), one possible approach is to use <b>RTCP-XR</b> [<a href="https://www.rfc-editor.org/rfc/rfc3611">RFC3611</a>]. Currently, WebRTC already supports RTCP-XR, but the offer generated by browser doesn't contain it. We hope the browser adds an API to enable the RTCP-XR.</p>

      <p><a href="https://github.com/w3c/webrtc-extensions/issues/165">Related issue</a></p>
      
    </section>

  </section>



</body>

</html>
